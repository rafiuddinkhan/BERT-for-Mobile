{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "lIYdn1woOS1n",
    "outputId": "3bf91ef7-3b11-4957-c25c-668aa9a0279b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 15 02:24:05 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Iq4_cao7CnnY",
    "outputId": "9cbb01ec-d333-4327-d616-f505cd1e5922"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nsG5QOFh-AXD"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/tensorflow/examples/master/tensorflow_examples/lite/model_maker/core/task/hub_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "DAigr1DgCq2J",
    "outputId": "4d26116a-77c5-4ca1-c6d3-067a566726e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.4.0-dev20200810\n",
      "Eager mode:  True\n",
      "WARNING:tensorflow:From <ipython-input-2-7b56c0c07964>:21: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from hub_loader import HubKerasLayerV1V2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FxMSb-Y_Cw8K"
   },
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "      fname='SST-2.zip',\n",
    "      origin='https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8',\n",
    "      extract=True)\n",
    "data_dir = os.path.join(os.path.dirname(data_dir), 'SST-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nQ-kL8H3Czli"
   },
   "outputs": [],
   "source": [
    "train = os.path.join(data_dir, \"train.tsv\")\n",
    "valid = os.path.join(data_dir, \"dev.tsv\")\n",
    "test = os.path.join(data_dir, \"test.tsv\")\n",
    "\n",
    "train_dataset = pd.read_csv(train, sep='\\t')\n",
    "valid_dataset = pd.read_csv(valid, sep='\\t')\n",
    "test_dataset = pd.read_csv(test, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "eKOi4G3tC3Ua",
    "outputId": "5fae2ab8-b254-42b5-af85-7f90d5883492"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "g22KqAq8C5Yb",
    "outputId": "d7f792e2-8be9-472b-9d91-4131fb299310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67349,), (872,), (1821,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews = train_dataset['sentence'].values\n",
    "train_sentiments = train_dataset['label'].values\n",
    "\n",
    "valid_reviews = valid_dataset['sentence'].values\n",
    "valid_sentiments = valid_dataset['label'].values\n",
    "\n",
    "test_reviews = test_dataset['sentence'].values\n",
    "\n",
    "train_reviews.shape, valid_reviews.shape, test_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1xYoz8TWC627"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OHF6OrjJC_MM"
   },
   "outputs": [],
   "source": [
    "# Referred from here - https://github.com/dipanjanS/deep_transfer_learning_nlp_dhs2019/blob/master/notebooks/5%20-%20Transformers%20-%20BERT.ipynb\n",
    "import tqdm\n",
    "\n",
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "    \n",
    "    all_ids, all_masks, all_segments= [], [], []\n",
    "    for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        if len(tokens) > max_seq_length-2:\n",
    "            tokens = tokens[0 : (max_seq_length-2)]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(ids) < max_seq_length:\n",
    "            ids.append(0)\n",
    "            masks.append(0)\n",
    "        segments = [0] * max_seq_length\n",
    "        all_ids.append(ids)\n",
    "        all_masks.append(masks)\n",
    "        all_segments.append(segments)\n",
    "    encoded = np.array([all_ids, all_masks, all_segments])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "P3DcVeOYIdhn",
    "outputId": "cd1d4b97-da61-4eba-b387-dcd689b15eb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features: 100%|██████████| 67349/67349 [00:13<00:00, 4959.32it/s]\n",
      "Converting docs to features: 100%|██████████| 872/872 [00:00<00:00, 3253.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: (67349, 128) (67349, 128) (67349, 128)\n",
      "Val Features: (872, 128) (872, 128) (872, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "train_features_ids, train_features_masks, train_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                               train_reviews, \n",
    "                                                                                               max_seq_length=MAX_SEQ_LENGTH)\n",
    "val_features_ids, val_features_masks, val_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                         valid_reviews, \n",
    "                                                                                         max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "print('Train Features:', train_features_ids.shape, train_features_masks.shape, train_features_segments.shape)\n",
    "print('Val Features:', val_features_ids.shape, val_features_masks.shape, val_features_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2qOcNEU7BFoH"
   },
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets for better performance\n",
    "train_ds = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(((train_features_ids, train_features_masks, train_features_segments), train_sentiments))\n",
    "    .shuffle(2048)\n",
    "    .batch(24)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "    \n",
    "valid_ds = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(((val_features_ids, val_features_masks, val_features_segments), valid_sentiments))\n",
    "    .batch(24)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "F3I6iAdX_JaD",
    "outputId": "cdaa0837-608a-420f-91d6-fa9043944d42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/1'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/1, Total size: 103.86MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hub_keras_layer_v1v2 (HubKerasL (None, 512)          24581888    input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 input_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      hub_keras_layer_v1v2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,779,265\n",
      "Trainable params: 24,779,265\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reference - https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/core/task/model_spec.py\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(\n",
    "      shape=(MAX_SEQ_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "input_mask = tf.keras.layers.Input(\n",
    "    shape=(MAX_SEQ_LENGTH,), dtype=tf.int32, name='input_mask')\n",
    "input_type_ids = tf.keras.layers.Input(\n",
    "    shape=(MAX_SEQ_LENGTH,), dtype=tf.int32, name='input_type_ids')\n",
    "  \n",
    "bert_model = HubKerasLayerV1V2(\n",
    "    'https://tfhub.dev/google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/1',\n",
    "    signature='tokens',\n",
    "    output_key='pooled_output',\n",
    "    trainable=True)\n",
    "\n",
    "pooled_output = bert_model({\n",
    "    'input_ids': input_word_ids,\n",
    "    'input_mask': input_mask,\n",
    "    'segment_ids': input_type_ids\n",
    "})\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], \n",
    "                       outputs=output)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=3e-5), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "Qr0KHCyDJA62",
    "outputId": "305c4a83-5369-4168-86da-a20572bf474e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2807/2807 [==============================] - 359s 128ms/step - loss: 0.5032 - accuracy: 0.7654 - val_loss: 0.2402 - val_accuracy: 0.9048\n",
      "Epoch 2/3\n",
      "2807/2807 [==============================] - 306s 109ms/step - loss: 0.1580 - accuracy: 0.9423 - val_loss: 0.2441 - val_accuracy: 0.9083\n",
      "Epoch 3/3\n",
      "2807/2807 [==============================] - 305s 109ms/step - loss: 0.1010 - accuracy: 0.9656 - val_loss: 0.2861 - val_accuracy: 0.9025\n",
      "Training took 971.4864466190338 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=3)\n",
    "end = time.time()\n",
    "print(\"Training took {} seconds.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilebert/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilebert/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir mobilebert\n",
    "model.save(\"mobilebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26698576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"mobilebert\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open(\"mobilebert_2_sst_seq_128.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 26M Oct 15 02:42 mobilebert_2_sst_seq_128.tflite\n"
     ]
    }
   ],
   "source": [
    "!ls -lh mobilebert_2_sst_seq_128.tflite"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ALBERT_Keras",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
